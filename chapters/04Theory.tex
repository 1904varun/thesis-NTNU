%equations, bib. \\

To determine the existence and abundance of different fish species, marine researchers have utilized a range of approaches for a long time. These strategies include the use of human-held video cameras and, more recently, nets put in the ocean to capture and analyze fish. Other methods include human underwater observation and photography \cite{spampinato2008detecting}. Underwater video is now mostly utilized to study marine and river ecosystems while also observing animal abundance and behavior in the context of environmental monitoring. Because visual perception is an inherent human trait, optical video provides comprehensive information in an easy-to-understand format. It has been successful to automate similar monitoring applications, such as video surveillance, utilizing computer vision and machine learning. Underwater, there are sudden changes in light, uneven spectrum propagation, low contrast, floating plants as clutter, and changes in visibility brought on by turbidity. The majority of studies on coral reef fish species from public datasets like Fish4Knowledge have focused on coral reef fish detection in underwater footage using machine learning or deep learning approaches \cite{xu2018underwater}. \\

Deep learning with neural networks has been a concept that has been around for many years. It originated in 1998 when researchers LeCun et al. \cite{lecun1998gradient} introduced the idea. One significant development in this field was the creation of LeNet5, a five-layer classifier based on Convolutional Neural Networks (CNN). However, the real progress in deep learning has been witnessed in recent years, mainly due to the significant advancements in computing power and the explosion of big data. The foundation of deep learning lies in the abundance of big data collected from various fields of study. Learning from vast amounts of data is crucial in this domain. It is only through the availability of sufficiently large datasets that deep learning models can overcome the problem of overfitting, which occurs when a model becomes too specialized to the training data and fails to generalize well to new data. Moreover, the improved processing power resulting from technological advancements has accelerated the otherwise time-consuming training process of deep learning models.
Deep learning-based methods have gained popularity across numerous sectors, offering several advantages over traditional object recognition and computer vision techniques. The implementation of deep learning has shown significant performance improvements in various robotics systems \cite{cui2020fish}. These advancements demonstrate the potential and effectiveness of deep learning in practical applications. \\

In order to speed up response times and conserve bandwidth, edge computing is a distributed computing paradigm that moves computation and data storage closer to the point of demand. Due to its ability to transfer and analyse huge data at low latency, it is especially helpful in underwater applications. In terms of applications in the underwater environment, edge computing can be used to process data from underwater sensors and devices, such as those used for oceanographic research or monitoring marine life. This can include tasks such as image recognition and classification, which are important for studying marine ecosystems. Additionally, edge computing can be used for real-time monitoring and control of underwater vehicles and equipment. By using edge computing to process data from underwater cameras, researchers can identify and classify different types of marine life based on their appearance. This can be useful for studying the distribution and abundance of different species, as well as for monitoring changes in the ecosystem over time. Image classification is a key application of machine learning in underwater applications, as it enables researchers to identify and classify different types of marine life based on their appearance. This can be useful for studying the distribution and abundance of different species, as well as for monitoring changes in the ecosystem over time
 \cite{periola2022edge}.
 Researchers can use an underwater camera system equipped with edge computing capabilities to capture real-time images of marine life and collect data. This could involve using underwater cameras or other sensors to capture images of different types of marine life in their natural habitats. The images would then need to be labeled with information about the species depicted in each image. Once the dataset has been collected and labeled, researchers can use it to train a CNN model. This involves feeding the model a set of training images along with their corresponding labels, and adjusting the model's parameters so that it learns to recognize patterns and features that are characteristic of each species and then use the trained CNN model to classify the images on-the-fly  \cite{periola2022edge}.


Fish4Knowledge is a program that receives funding from the European Union Seventh Framework. This initiative utilizes ten underwater cameras to capture live video feeds, serving as a testbed for exploring techniques applicable to multiple video stream acquisition, storage, analysis, and querying. The wealth of information gathered through this project is compiled into a comprehensive public database spanning two years. This database includes video summaries showcasing the various fish species observed, accompanied by relevant characteristics. To enhance accessibility and usability, the Fish4Knowledge project focuses on developing professional web-based interfaces. These interfaces provide marine researchers with unparalleled access to both current and archived films, as well as previously extracted data. By utilising these interfaces, researchers can delve into the vast collection of videos and associated information to facilitate their studies and investigations \cite{fisher2016fish4knowledge}. Some of the projects which have used this dataset to develop their solutions are:

\begin{itemize}
    \item In the study conducted by Choi \cite{choi2015fish}, the research focused on fish identification in underwater video using deep convolutional neural networks (CNNs). The unique challenge in this work arose from the utilization of underwater video images, which presented additional complexities requiring pre-processing and post-processing steps to be incorporated. To tackle these challenges, Choi combined a foreground detection approach with selective search techniques for potential fish item window detection. This merged approach aimed to accurately identify regions of interest within the underwater videos that potentially contained fish. By effectively detecting these candidate windows, the subsequent steps of classification and identification could be carried out more efficiently. In the training phase, a CNN was employed to classify different fish species. However, due to the scarcity of labeled underwater video data specifically for fish classification, the CNN model was trained using data from other generic object classification tasks. This transfer learning approach allowed the network to leverage pre-existing knowledge and generalize it to the task of fish species identification.\\
    The final identification results were obtained by combining the outputs from the CNN classification findings with further enhancements. This post-processing step aimed to refine and improve the accuracy of the classification results, ensuring reliable and precise identification of fish species within the underwater videos. Overall, Choi's research highlighted the intricacies of fish identification in underwater video compared to standard picture classification tasks. The integration of foreground detection, selective search, and deep CNNs demonstrated the complexity and importance of addressing pre-processing and post-processing stages to achieve robust fish species identification in the challenging underwater environment.
    \item Li et al. \cite{li2015fast} sought to leverage the exceptional detection accuracy of Fast R-CNN to develop an efficient and accurate fish detection and recognition system for underwater images. The primary objective of their work was to contribute to the development of automated fish identification systems that could assist marine researchers in estimating fish numbers, abundance, and gaining a deeper understanding of marine geography and biology. By utilizing the Fast R-CNN framework, Li et al. aimed to achieve both high detection accuracy and efficient processing speeds, addressing the need for real-time or near-real-time analysis of underwater images. The Fast R-CNN architecture combines a region proposal network with a CNN for object detection and recognition, enabling accurate localization and classification of fish species within the images.\\
    To evaluate the performance of their system, Li et al. conducted extensive experiments. The results demonstrated that their proposed detection system exhibited promising performance, with a higher mean average precision (mAP) compared to other existing methods such as Deformable Parts Models (DPM). Additionally, the system showed the potential to achieve faster processing speeds than the conventional R-CNN approach. This research contributes to the ongoing efforts to develop advanced automated tools that aid in the monitoring and conservation of aquatic environments.
    \item Zhang et al. \cite{zhang2016unsupervised} addressed the pressing need for an automated segmentation technique to generate baseline annotations of fish areas, facilitating the estimation of fish abundance in underwater environments. To tackle this challenge, they proposed an unsupervised underwater fish detection methodology that leveraged the power of deep learning technology. A key focus of their work was to develop a method that eliminated the requirement for manual annotation and allowed for real-time online learning. To achieve these objectives, Zhang et al. first optimized the algorithm for speed. They then devised a multi-step approach that incorporated motion flow segmentation and selective search to create candidate regions for fish detection. By utilizing motion flow segmentation, they aimed to distinguish moving objects, such as fish, from the background, improving the accuracy of subsequent detection steps.\\
    Selective search was employed to generate region proposals, which reduced the likelihood of incorrect labeling during the training phase. These region proposals were combined with the results of motion segmentation and fed into a convolutional neural network (CNN) for detection. This fusion of region proposals and motion segmentation yielded superior performance compared to using the separate components independently. To refine the detection results, Zhang et al. implemented a modified non-maximum suppression (NMS) algorithm. This technique effectively reduced the number of overlapping windows, enhancing the localization precision of detected fish instances. The modified NMS algorithm optimized the suppression process to ensure that complete fish objects were accurately identified while minimizing the presence of redundant or overlapping windows. By developing this unsupervised underwater fish detection method, Zhang et al. offered a valuable solution for automatically segmenting fish areas without relying on manual annotation. Their approach, which incorporated motion flow segmentation, selective search, and CNN-based detection with modified NMS, demonstrated improved performance and efficiency. This research contributes to the development of advanced techniques for fish identification and abundance estimation in underwater environments.
    \item In their work, Rathi et al. \cite{rathi2017underwater} employed Convolutional Neural Networks (CNNs) as a central component of their proposed technique, which aimed to enhance the efficiency and effectiveness of fish species classification, particularly when dealing with large datasets. By leveraging CNNs, their approach facilitated streamlined and robust operations for fish classification tasks. The process began with the pre-processing of underwater images, which involved several techniques such as Gaussian Blurring, Morphological Operations, Otsu's Thresholding, and Pyramid Mean Shifting. These pre-processing steps aimed to enhance the quality and clarity of the images, reducing noise and enhancing relevant features necessary for accurate classification. \\ 
    Following the pre-processing stage, the pre-processed images were fed into a CNN model for classification. The CNN architecture enabled the extraction of intricate features and patterns from the images, facilitating the identification and classification of different fish species. By leveraging the power of deep learning and CNNs, Rathi et al. achieved remarkable accuracy in their approach. According to their experimental findings, the suggested technique achieved an impressive accuracy rate of 96.29\% in classifying fish species. This accuracy surpassed the performance of other existing methods commonly employed for this purpose. The superiority of their proposed approach highlighted the efficacy and potential of utilizing CNNs in underwater fish classification tasks. By demonstrating the effectiveness and accuracy of their technique, Rathi et al. contributed to advancing the field of underwater fish species classification. Their approach, which incorporated CNNs and a series of pre-processing steps, showcased the capability of deep learning algorithms to handle large datasets and achieve superior classification results.
    \item In their study, Mandal et al. \cite{mandal2018assessing} highlighted the significant advantages of utilizing remote underwater video feeds for autonomous assessment of fish and species abundance. They emphasized that this approach offers substantial potential in terms of time and cost savings compared to traditional methods. To harness the full potential of this technology, the researchers employed an end-to-end deep learning technique to analyze the video streams and extract the necessary information for evaluation. Mandal et al. conducted a series of tests using various deep learning models and performed a comprehensive analysis of their performance. The objective was to assess the effectiveness of these models in accurately identifying and quantifying a diverse range of marine species from the video feeds.\\
    The results were highly encouraging. The researchers achieved an impressive mean average precision (mAP) of 82.4\% across a substantial number of marine species. This mAP value indicated the overall accuracy and reliability of the deep learning models in successfully detecting and classifying different species present in the underwater videos. The findings of this study demonstrate the potential of employing end-to-end deep learning techniques for autonomous fish and species abundance assessment using remote underwater video feeds. By leveraging the capabilities of deep learning models, Mandal et al. showcased the feasibility of extracting valuable information from video streams and achieving high levels of accuracy in species identification and abundance estimation. This research contributes to advancing the field of underwater monitoring and conservation by providing an efficient and effective approach for assessing marine biodiversity.
    \item Marini et al. \cite{marini2018tracking} introduced a novel and efficient video-automated approach to accurately track and estimate fluctuations in fish abundance under challenging real-world conditions, without the need to differentiate between various fish species. To achieve this, they developed a unique generic supervised machine learning framework for fish recognition in images based on their content. This framework was extensively tested across a range of lighting scenarios, variations in water turbidity, and even accounted for biofouling-induced changes on the camera housing. To ensure the robustness and generalization performance of their image classifier, Marini et al. employed a K-fold Cross-Validation framework. This approach enabled them to select the most relevant image attributes for fish recognition and develop an automated image classifier that could effectively handle varying environmental conditions. \\
    The proposed video-automated approach allowed for continuous monitoring of fish abundance, providing valuable insights into population dynamics and fluctuations. By utilizing the supervised machine learning framework, Marini et al. effectively addressed the challenges associated with fish recognition in diverse underwater environments. This approach not only eliminated the need for species differentiation but also demonstrated its effectiveness in accommodating variations in lighting, water turbidity, and biofouling. The research conducted by Marini et al. offered a robust and versatile solution for accurately tracking fish abundance in real-world conditions. The use of a generic supervised machine learning framework and the K-fold Cross-Validation technique ensured accurate and reliable fish recognition and counting, regardless of environmental variations. This study contributes to the development of automated approaches for underwater image analysis and provides a valuable tool for ecological research and fisheries management.
\end{itemize} \\

According to Xu and Matzner's study on underwater fish detection for water power applications \cite{xu2018underwater}, previous research in underwater fish optical analysis primarily focused on classifying coral fish in well-lit shallow seas or deep waters where fish populations were abundant and easily observable. However, there is a notable gap in the literature when it comes to detecting fish in more challenging underwater environments, particularly in the vicinity of marine and hydrokinetic (MHK) energy projects or river hydro power projects. These areas often present difficult conditions, such as high turbidity, fast water currents, and murky waters, where fish tend to have less distinct colors and are barely perceptible. Addressing this research gap is crucial due to the increasing interest in MHK and river hydro power projects, where assessing the potential impact on fish populations is vital. Xu and Matzner emphasize the need for accurate fish detection methods that can overcome the challenges of low visibility and dull-colored fish. By developing techniques based on deep learning algorithms, they aim to detect fish in underwater environments with improved accuracy and efficiency. \\
On the other hand, Nair et al. \cite{nair2018under} shed light on the challenges associated with underwater fish species recognition. They highlight the difficulty of collecting representative samples for underwater photos, as it involves dealing with poor image quality and uncontrolled environmental factors. Furthermore, existing feature extraction methods often require continuous human supervision, which can be time-consuming and labor-intensive. Manual examination of fish images and videos by marine biologists is a common practice to extract essential information, further adding to the overall effort required. To address these challenges, Nair et al. propose the development of automated methods for fish species recognition, reducing the reliance on manual intervention. Their research aims to explore innovative approaches and algorithms to streamline the process of fish analysis in underwater imagery. \\
In the field of underwater image processing, Raveendran et al. \cite{raveendran2021underwater} emphasize the critical role played by datasets of underwater images. These datasets serve as invaluable resources for advancing image processing methods in underwater environments. They enable researchers to develop and evaluate novel algorithms, improving fish detection, species recognition, and other related tasks. With access to comprehensive underwater image datasets, researchers can devise more sophisticated techniques that minimize the need for human oversight, resulting in more efficient analysis of underwater imagery.\\

Machine vision systems have become indispensable tools in aquaculture monitoring, offering numerous advantages such as non-intrusiveness, objectivity, and repeatability. However, traditional image processing techniques often struggle to yield satisfactory results in the complex underwater environment. The intricate nature of underwater conditions, such as variations in lighting, water turbidity, and biofouling, presents challenges for accurate data processing using conventional methods. To overcome these challenges, deep learning algorithms have gained significant attention in the field of underwater image processing. The remarkable feature extraction capabilities of deep learning algorithms make them highly suitable for handling the complexities of underwater imagery. By automatically learning and identifying relevant features from vast amounts of training data, deep learning algorithms can effectively analyze and interpret underwater images. The fusion of deep learning algorithms with machine vision techniques is crucial for advancing the automated monitoring of aquaculture systems. This integration enables the development of robust and efficient systems capable of performing tasks such as fish classification, detection, counting, behavior identification, and biomass estimation. The application of deep learning in these areas demonstrates the interdisciplinary nature of its impact on aquacultural machine vision systems \cite{li2022recent}. In the context of aquaculture, the acquisition and processing of image data can be time-consuming. To address this, motion detection techniques are utilized to extract relevant frames from video footage. However, manual processing is still required to analyze the extracted frames. To streamline this process and automate data extraction from images, machine vision techniques based on object recognition have proven instrumental. By accurately separating the subject of interest from the background, these techniques enable the application of computationally efficient approaches such as optical flow analysis and segmentation based on pixel characteristics. This automated data extraction not only improves efficiency but also enhances the accuracy of aquacultural data analysis \cite{monkman2019using}.\\

With the use of the Internet of Things (IoT), big data, cloud computing, artificial intelligence, and other cutting-edge information technologies, a new scientific field called "smart fish farming" seeks to increase resource efficiency and promote the expansion of a sustainably managed aquaculture industry. Additionally, real-time data collection, quantitative decision-making, intelligent control, precise investment, and individualized service have all contributed to the formation of a new fisheries production mode. Data and information are the cornerstones of smart fish farming. The aggregation and sophisticated analyses of all or some of the data will lead to the ability to make decisions with a scientific basis. However, the massive amount of data produced by smart fish farming poses a variety of challenges, including various sources, several formats, and complex data. Diverse sources are used to compile data about the people, the environment, the tools, the fish, and the breeding process. There are numerous formats accessible, including text, image, and audio. Data complexity is caused by various species, cultural eras, and styles. The aforementioned high-dimensional, nonlinear, and massive data present a very challenging problem \cite{yang2021deep}. \\

Researchers have been able to contribute to some important fields where the application of deep learning, computer vision and fish detection can be observed. To list a few, we can consider:
\begin{itemize}
    \item \textbf{Live fish identification}: Fish identification is a crucial step in the development of intelligent breeding management tools or systems since precise and automated live fish identification can provide information for managing future output. MV has the advantage of providing inexpensive, long-term, nondestructive observation \cite{zhou2018handling}. In order to detect live fish, DL is typically employed to determine whether a particular object is a fish. In a time when enormous amounts of visual data can be quickly obtained, deep learning has become a helpful machine vision solution \cite{(salman2016fish}. Deep learning has a fundamental flaw in that it requires a large amount of annotated training data, and gathering and annotating a large quantity of images takes a lot of time and effort.
    \item \textbf{Species identification}: There are approximately 33000 different species of fish \cite{oosting2019unlocking}. Species categorization in aquaculture is beneficial for yield forecast, production management, and ecosystem monitoring, according to Alcaraz et al \cite{alcaraz2015herbivory}. Usually, various fish species may be distinguished from one another by their visual qualities, such as size, shape, and color. However, due to differences in light intensity, fish movement, and similarity in forms and patterns across several species, effective fish species categorization is challenging. Deep learning algorithms are able to recognize the specific visual characteristics of animals that are resilient to changes in their environment \cite{dos2019improving}.
    \item \textbf{Analysis of behaviour}: Since fish are sensitive to environmental changes, they respond to them by changing their behavior in a variety of ways \cite{mahesh2008feasibility}. Additionally, behavior serves as a helpful benchmark indicator for fish welfare and harvesting \cite{zion2012use}. By monitoring pertinent behavior, especially for unusual behaviors, in a non-destructive way, one can gain an early warning of fish status \cite{rillahan2011behavior}. Fish activity must be continuously observed in order to understand their status and make decisions about when to catch and feed them \cite{papadakis2012computer}.
    \item \textbf{Size estimation}: Fish physical characteristics including length, breadth, weight, and area may be assessed more precisely when machine vision and DL are combined. The bulk of reported uses are either semi-supervised or supervised \cite{marini2018tracking}. For example, the Mask R-CNN architecture was used to calculate the sizes of saithe, blue whiting, redfish, Atlantic mackerel, velvet belly lanternshark, Norway pout, Atlantic herring, and European hake. Another indirect method for determining fish size involves using a DL model to first determine the fish's head and tail, and then extrapolating the length of the fish from that data. While adding to the workload, this approach is suited for more intricate images \cite{tseng2020automatic}.
    \item \textbf{Feeding decision-making}: The productivity and breeding expenses of intensive aquaculture are directly impacted by the quantity of fish supplied \cite{chen2020feed}. Fish growth will be affected by insufficient food, whereas excessive feeding will reduce productivity. Overfeeding also reduces feed conversion efficiency and contaminates the environment with leftover bait. Therefore, enhancing the feeding process can result in substantial economic gains \cite{zhou2018intelligent}.
    \item \textbf{Water quality prediction:} Dissolved oxygen and other indices of water quality are best predicted over time. With the right care, DL models like LSTM, DBN, and others may effectively mine time sequence data and deliver results that are satisfactory. How to use DL models to avoid or lessen the negative effects of uncertainty factors on prediction outcomes will therefore be a crucial area for improvement in jobs requiring the prediction of water quality \cite{yang2021deep}.
\end{itemize}

In order to effectively identify and categorize various fish species, it is necessary to automatically extract characteristics from data. This is where machine learning and deep learning play a significant and important role in the categorization of fish. This is crucial in aquaculture, where the capacity to recognize fish species fast and precisely can boost productivity, cut costs, and guarantee the quality of the finished product. Other applications in aquaculture, including as behavior analysis, feeding choices, size or biomass estimation, and water quality prediction, can also be done using machine learning/deep learning in addition to fish classification. Aquaculture professionals may improve results by using these tools to better understand their operations and make data-driven decisions \cite{DLfishfarming}. Large datasets of fish photos can be used to train machine learning algorithms to automatically identify various species based on their distinctive characteristics, such as color patterns, body shapes, and fin structures. Machine learning and deep learning can assist fish farms optimize their feeding tactics by estimating the ideal amount of feed needed for each fish depending on their size and weight, in addition to increasing the accuracy of fish classification. As a result, waste can be reduced and aquaculture operations can operate more effectively overall \cite{knausgard2021temperate}. Researchers can create models that can precisely classify various species based on their physical traits by analyzing fish photos with machine learning algorithms. This can make it simpler for farmers to monitor the expansion and growth of their fish populations and to spot any potential health concerns or environmental issues that might be harming them \cite{zhao2021application}. Deep learning techniques such as convolutional neural networks (CNNs) have been used to classify different species of fish based on images captured by underwater cameras and the following are some work related to deep learning and smart fish farming that finds fish classification is one of the most popular fields of application \cite{DLfishfarming}:
\begin{itemize}
    \item Fish species recognition using deep learning techniques by Sarker et. al. \cite{sarker2018fish} used a CNN to classify six different species of fish based on images captured by an underwater camera system. The study was conducted in Bangladesh and used a dataset of 1,200 images of six different fish species commonly found in the region. The authors trained a CNN using the dataset and achieved an accuracy rate of over 90\% for all six species.
    \item Fish classification using deep convolutional neural network with transfer learning by Kwon et. al. \cite{kwon2019fish} is another study that used a combination of CNNs and SVMs to classify four different species of fish based on images captured by an underwater camera system. The study was conducted in South Korea and used a dataset of 1,000 images of four different fish species commonly found in the region. The authors trained a CNN using transfer learning and then used an SVM to classify the images based on the features extracted by the CNN. The combined approach achieved an accuracy rate of over 95\%.
    \item Fish detection and species classification in underwater environments using deep learning with temporal information by Jalal et. al. \cite{jalal2020fish} is a study where the authors used a dataset of underwater fish images captured by an underwater camera system. The authors used a deep learning model that combined a CNN with an LSTM to capture temporal information. The authors achieved an accuracy rate of 96.7\% for fish detection and 92.3\% for fish species classification using their proposed method. 
    \item  A novel deep learning approach for fish species recognition based on convolutional neural network and softmax regression by Sun et. al. \cite{sun2018novel} also used a dataset of fish images captured by an underwater camera system and the authors used a CNN model combined with softmax regression. The authors achieved an accuracy rate of 96\% for fish species recognition using their proposed method and also noted the challenges in underwater fish recognition include variations in lighting conditions and water quality.
    \item Image-based monitoring of jellyfish using deep learning architecture by Kim et. al. \cite{kim2016image} used a dataset of jellyfish images captured by an underwater camera system and the authors used a CNN model combined with transfer learning. The authors achieved an accuracy rate of 95.5\% for jellyfish detection using their proposed method and noted that challenges in jellyfish recognition include variations in jellyfish appearance due to changes in lighting conditions and water quality.
    \item Fish species recognition using deep learning techniques by Hossain et al. \cite{8711657} used a dataset of 10,000 images of 10 different fish species, which were captured using underwater cameras in natural environments. They used a CNN model which consisted of several layers, including convolutional layers, pooling layers, and fully connected layers. The authors also used data augmentation techniques to increase the size of their dataset and improve the performance of their model and achieved an accuracy rate of 98\% for fish species recognition. They also noted various challenges such as some fish species were more difficult to classify than others due to variations in their physical characteristics such as color and shape and limitations associated with using underwater cameras to capture images of fish, such as poor lighting conditions or low image quality in some cases.
    \item Fish biomass estimation using machine learning techniques by Singh et al. \cite{singh2019fish} collected a dataset of 1,200 images by capturing images of fish in aquaculture ponds using underwater cameras. They used machine learning algorithm called Random Forest to estimate the biomass of fish in aquaculture ponds and achieved an accuracy rate of 95\%. The authors noted that there were some challenges associated with this task, such as variations in lighting conditions and image quality, which can affect the accuracy of the biomass estimates.
    \item Fish recognition using convolutional neural networks by Al-Ali et al. \cite{al2018fish} used a deep learning approach to recognize and classify fish species based on images captured using underwater cameras. The authors used a convolutional neural network (CNN) model to classify the fish images and also used data augmentation techniques to increase the size of their dataset and improve the performance of their model. They achieved an accuracy rate of 92\% by using a dataset of 1,000 images of 10 different fish species. Variations in lighting conditions and image quality was a challenge noted which can affect the accuracy of fish recognition models.
\end{itemize}

Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) are widely recognized as popular deep learning models that are extensively used in edge computing. Edge computing involves deploying a network of interconnected computing nodes in close proximity to end devices. This approach proves to be highly advantageous in fulfilling the demanding computational needs and low-latency requirements of deep learning tasks on edge devices. Moreover, edge computing offers numerous additional benefits, including enhanced privacy, improved bandwidth efficiency, and increased scalability. By leveraging CNNs and RNNs in edge computing, significant advancements have been made in processing data directly on edge devices. CNNs are particularly effective for image and video analysis tasks, as they excel in extracting meaningful features from visual data. RNNs, on the other hand, excel in sequential data processing, making them ideal for applications involving speech recognition, natural language processing, and time-series analysis.\cite{8763885}. 

\todo[inline]{Add a conclusion here?}



